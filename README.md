# ğŸ§  Local LLM Desktop Assistant with System Monitor

A **feature-rich desktop AI assistant** built using **Python**, **Tkinter**, and **Ollama**, enabling **local Large Language Model (LLM) inference** without relying on cloud APIs.
The application integrates **AI chat**, **voice input/output**, and a **real-time system monitoring dashboard** into a single desktop interface.

This project was developed as part of an **academic course project** and demonstrates practical implementation of **local AI deployment**, **GUI development**, and **system resource monitoring**.

---

## ğŸ–¼ï¸ Application Preview

> Add screenshots inside a `screenshots/` folder and update filenames if needed.

### ğŸ”¹ Main Chat Interface

![Main Chat UI](ss/main.png)

### ğŸ”¹ System Monitor Dashboard

![System Monitor](ss/system.png)

### ğŸ”¹ Chat History Viewer

![Chat History](ss/ans.png)


### ğŸ”¹ Code Interaction

![Voice Input](ss/code.png)

---

## ğŸ“ Project Folder Structure

```
.
â”œâ”€â”€ 1414 Project Proposal.docx
â”œâ”€â”€ 1414 Project Proposal.pdf
â”œâ”€â”€ Project Report Local LLM 1414.docx
â”œâ”€â”€ Project Report Local LLM 1414.pdf
â”‚
â”œâ”€â”€ base.py
â”œâ”€â”€ project.py
â”œâ”€â”€ Only_LLM.py
â”œâ”€â”€ System_Monitor.py
â”‚
â”œâ”€â”€ mic_icon.png
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.txt
â”œâ”€â”€ README.md
â””â”€â”€ screenshots/
    â”œâ”€â”€ main_ui.png
    â”œâ”€â”€ voice_input.png
    â”œâ”€â”€ system_monitor.png
    â””â”€â”€ chat_history.png
```

---

## ğŸ“„ File Overview

### ğŸ“˜ Documentation

* **1414 Project Proposal (.docx / .pdf)**
  Contains the project idea, objectives, problem statement, and proposed methodology.

* **Project Report Local LLM 1414 (.docx / .pdf)**
  Final academic report including system architecture, implementation, results, and discussion.

---

### ğŸ§  Application Source Code

* **`project.py`**
  Main application file. Launches the complete AI assistant with:

  * LLM chat
  * Voice input/output
  * Model selection
  * Chat history
  * Real-time system monitoring

* **`base.py`**
  Shared core logic including:

  * Prompt templates
  * LLM configuration
  * Reusable utilities

* **`Only_LLM.py`**
  Lightweight version focusing **only on local LLM interaction**, without system monitoring or advanced UI features.

* **`System_Monitor.py`**
  Standalone system resource monitor displaying:

  * CPU usage
  * Memory usage
  * GPU memory usage (NVIDIA)

---

### ğŸ™ Assets & Configuration

* **`mic_icon.png`**
  Icon used for the microphone button in the UI.

* **`requirements.txt`**
  List of all required Python packages.

* **`setup.txt`**
  Environment setup notes and additional instructions.

---

## ğŸš€ Features

### ğŸ¤– Local AI Chat

* Fully **offline LLM inference** using Ollama
* Supports multiple models
* Context-aware responses
* Chat history saved in Markdown format

### ğŸ¤ Voice Support

* Speech-to-text using `SpeechRecognition`
* Text-to-speech using `pyttsx3`
* Toggle voice output on/off

### ğŸ“Š System Monitoring

* Live CPU usage graph
* Live RAM usage graph
* GPU memory usage (NVIDIA only)
* Embedded Matplotlib graphs inside Tkinter UI

### ğŸ¨ User Interface

* Dark-themed desktop UI
* Model selection dropdown
* Keyboard support (Enter to send)
* Dedicated chat history viewer

---

## ğŸ§© Supported LLM Models

Any model installed in Ollama can be used, including:

* `llama3.2`
* `llama3.1`
* `qwen2.5-coder`
* `qwen2`
* `mistral`
* `gemma`

---

## ğŸ›  Installation & Setup

### 1ï¸âƒ£ Install Ollama

Download from:

```
https://ollama.com
```

Pull a model:

```bash
ollama pull llama3.2
```

---

### 2ï¸âƒ£ Install Python Dependencies

```bash
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Run the Application

Full application:

```bash
python project.py
```

LLM-only version:

```bash
python Only_LLM.py
```

System monitor only:

```bash
python System_Monitor.py
```

---

## ğŸ” Privacy & Security

* All AI inference runs **locally**
* No cloud-based LLM APIs are used
* No chat data is transmitted externally
* Internet access is required **only** for speech recognition (optional)

---

## ğŸ“ Academic Relevance

This project demonstrates:

* Local deployment of LLMs
* Desktop GUI application design
* Voice-enabled human-computer interaction
* System resource monitoring
* Modular and maintainable Python architecture

---

## ğŸ‘¤ Author

**Bishwajit Kumar Chakraborty**
B.Sc. in Computer Science & Engineering

* GitHub: [https://github.com/Bishwajit-2810](https://github.com/Bishwajit-2810)
* LinkedIn: [https://www.linkedin.com/in/bishwajit-chakraborty/](https://www.linkedin.com/in/bishwajit-chakraborty/)

---

## ğŸ“œ License

This project is intended for **educational and research purposes**.
Feel free to study, modify, and extend it.
